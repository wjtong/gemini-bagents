#!/usr/bin/env python3
"""
æ•°æ®åˆ†æåŠŸèƒ½æµ‹è¯•è„šæœ¬

è¿™ä¸ªè„šæœ¬ç”¨äºæµ‹è¯•æ•°æ®åˆ†æåŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œï¼ˆå½“å‰ä¸ºdummyå®ç°ï¼‰ã€‚
"""

import os
import sys
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.agent.configuration import Configuration
from src.agent.utils import get_table_schema
from src.agent.graph import graph
from langchain_core.messages import HumanMessage

def test_configuration():
    """æµ‹è¯•é…ç½®åŠ è½½"""
    print("ğŸ” æµ‹è¯•é…ç½®åŠ è½½...")
    
    load_dotenv()
    config = Configuration()
    
    try:
        print(f"âœ… é…ç½®åŠ è½½æˆåŠŸ")
        print(f"   æŸ¥è¯¢ç”Ÿæˆæ¨¡å‹: {config.query_generator_model}")
        print(f"   åæ€æ¨¡å‹: {config.reflection_model}")
        print(f"   å›ç­”æ¨¡å‹: {config.answer_model}")
        return True
    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {str(e)}")
        return False

def test_table_schema():
    """æµ‹è¯•è¡¨ç»“æ„è·å–"""
    print("\nğŸ” æµ‹è¯•è¡¨ç»“æ„è·å–...")
    
    load_dotenv()
    config = Configuration()
    
    try:
        schema = get_table_schema(config)
        print("âœ… è¡¨ç»“æ„è·å–æˆåŠŸ")
        print(f"   å½“å‰è¿”å›ç©ºå­—å…¸ï¼ˆdummyå®ç°ï¼‰")
        return True
    except Exception as e:
        print(f"âŒ è¡¨ç»“æ„è·å–å¤±è´¥: {str(e)}")
        return False

def test_data_analysis_node():
    """æµ‹è¯•æ•°æ®åˆ†æèŠ‚ç‚¹"""
    print("\nğŸ” æµ‹è¯•æ•°æ®åˆ†æèŠ‚ç‚¹...")
    
    load_dotenv()
    
    try:
        # æµ‹è¯•æ•°æ®åˆ†ææŸ¥è¯¢
        test_query = "è®¡ç®—æ¯ä¸ªäº§å“ç±»åˆ«çš„æ€»é”€å”®é¢"
        print(f"   æµ‹è¯•æŸ¥è¯¢: {test_query}")
        
        messages = [HumanMessage(content=test_query)]
        result = graph.invoke({
            "messages": messages,
            "initial_search_query_count": 1,
            "max_research_loops": 1,
            "reasoning_model": "gpt-4o",
        })
        
        if result.get("messages"):
            print("âœ… æ•°æ®åˆ†æèŠ‚ç‚¹æµ‹è¯•æˆåŠŸ")
            print(f"   ç”Ÿæˆäº†å›ç­”")
            return True
        else:
            print("âŒ æ•°æ®åˆ†æèŠ‚ç‚¹æ²¡æœ‰ç”Ÿæˆå›ç­”")
            return False
            
    except Exception as e:
        print(f"âŒ æ•°æ®åˆ†æèŠ‚ç‚¹æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def test_task_type_determination():
    """æµ‹è¯•ä»»åŠ¡ç±»å‹åˆ¤æ–­"""
    print("\nğŸ” æµ‹è¯•ä»»åŠ¡ç±»å‹åˆ¤æ–­...")
    
    load_dotenv()
    
    try:
        # æµ‹è¯•æ•°æ®åˆ†ææŸ¥è¯¢
        data_query = "è®¡ç®—æ¯ä¸ªäº§å“ç±»åˆ«çš„æ€»é”€å”®é¢"
        print(f"   æ•°æ®åˆ†ææŸ¥è¯¢: {data_query}")
        
        messages = [HumanMessage(content=data_query)]
        result = graph.invoke({
            "messages": messages,
            "initial_search_query_count": 1,
            "max_research_loops": 1,
            "reasoning_model": "gpt-4o",
        })
        
        task_type = result.get("task_type", "unknown")
        print(f"   åˆ¤æ–­çš„ä»»åŠ¡ç±»å‹: {task_type}")
        
        # æµ‹è¯•ç½‘ç»œæœç´¢æŸ¥è¯¢
        web_query = "AIæŠ€æœ¯çš„æœ€æ–°å‘å±•"
        print(f"   ç½‘ç»œæœç´¢æŸ¥è¯¢: {web_query}")
        
        messages = [HumanMessage(content=web_query)]
        result = graph.invoke({
            "messages": messages,
            "initial_search_query_count": 1,
            "max_research_loops": 1,
            "reasoning_model": "gpt-4o",
        })
        
        task_type = result.get("task_type", "unknown")
        print(f"   åˆ¤æ–­çš„ä»»åŠ¡ç±»å‹: {task_type}")
        
        print("âœ… ä»»åŠ¡ç±»å‹åˆ¤æ–­æµ‹è¯•æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ ä»»åŠ¡ç±»å‹åˆ¤æ–­æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ•°æ®åˆ†æåŠŸèƒ½æµ‹è¯•\n")
    print("æ³¨æ„ï¼šå½“å‰ä½¿ç”¨dummyå®ç°ï¼Œå®é™…æ•°æ®åˆ†æåŠŸèƒ½å·²æš‚æ—¶ç§»é™¤")
    print("=" * 60)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    load_dotenv()
    required_vars = [
        "OPENAI_API_KEY",
    ]
    
    missing_vars = []
    for var in required_vars:
        if not os.getenv(var):
            missing_vars.append(var)
    
    if missing_vars:
        print(f"âŒ ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}")
        print("è¯·å‚è€ƒ README.md æ–‡ä»¶è¿›è¡Œé…ç½®")
        return
    
    print("âœ… ç¯å¢ƒå˜é‡æ£€æŸ¥é€šè¿‡")
    
    # è¿è¡Œæµ‹è¯•
    tests = [
        test_configuration,
        test_table_schema,
        test_data_analysis_node,
        test_task_type_determination,
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        if test():
            passed += 1
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ•°æ®åˆ†æåŠŸèƒ½é…ç½®æ­£ç¡®ã€‚")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œä¾èµ–ã€‚")

if __name__ == "__main__":
    main()
